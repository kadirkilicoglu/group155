{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7qrr7-8ZEZp",
        "outputId": "622723cb-e9d1-43a9-8f96-31873ce29f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.4057 - loss: 1.1758 - val_accuracy: 0.5294 - val_loss: 0.9854\n",
            "Epoch 2/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4961 - loss: 0.9923 - val_accuracy: 0.6863 - val_loss: 0.8537\n",
            "Epoch 3/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5762 - loss: 0.8846 - val_accuracy: 0.7451 - val_loss: 0.7412\n",
            "Epoch 4/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6501 - loss: 0.8045 - val_accuracy: 0.7843 - val_loss: 0.6577\n",
            "Epoch 5/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7107 - loss: 0.6669 - val_accuracy: 0.7843 - val_loss: 0.5980\n",
            "Epoch 6/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7416 - loss: 0.6180 - val_accuracy: 0.8039 - val_loss: 0.5560\n",
            "Epoch 7/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7897 - loss: 0.5325 - val_accuracy: 0.8235 - val_loss: 0.5255\n",
            "Epoch 8/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.5257 - val_accuracy: 0.8725 - val_loss: 0.5049\n",
            "Epoch 9/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4859 - val_accuracy: 0.8824 - val_loss: 0.4914\n",
            "Epoch 10/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.4489 - val_accuracy: 0.8824 - val_loss: 0.4737\n",
            "Epoch 11/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8627 - loss: 0.4041 - val_accuracy: 0.8824 - val_loss: 0.4609\n",
            "Epoch 12/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8909 - loss: 0.3478 - val_accuracy: 0.8922 - val_loss: 0.4458\n",
            "Epoch 13/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.3586 - val_accuracy: 0.8824 - val_loss: 0.4251\n",
            "Epoch 14/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8939 - loss: 0.3223 - val_accuracy: 0.9118 - val_loss: 0.4126\n",
            "Epoch 15/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8974 - loss: 0.3297 - val_accuracy: 0.9020 - val_loss: 0.3990\n",
            "Epoch 16/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.3057 - val_accuracy: 0.9216 - val_loss: 0.3849\n",
            "Epoch 17/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 0.2996 - val_accuracy: 0.9216 - val_loss: 0.3763\n",
            "Epoch 18/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9140 - loss: 0.2564 - val_accuracy: 0.9216 - val_loss: 0.3719\n",
            "Epoch 19/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9276 - loss: 0.2325 - val_accuracy: 0.9216 - val_loss: 0.3625\n",
            "Epoch 20/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9172 - loss: 0.2445 - val_accuracy: 0.9314 - val_loss: 0.3587\n",
            "Epoch 21/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9314 - loss: 0.2147 - val_accuracy: 0.9118 - val_loss: 0.3505\n",
            "Epoch 22/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9338 - loss: 0.1974 - val_accuracy: 0.9314 - val_loss: 0.3473\n",
            "Epoch 23/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9269 - loss: 0.2416 - val_accuracy: 0.9118 - val_loss: 0.3331\n",
            "Epoch 24/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.2144 - val_accuracy: 0.9314 - val_loss: 0.3320\n",
            "Epoch 25/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.1914 - val_accuracy: 0.9118 - val_loss: 0.3189\n",
            "Epoch 26/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.1760 - val_accuracy: 0.9314 - val_loss: 0.3131\n",
            "Epoch 27/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9504 - loss: 0.1490 - val_accuracy: 0.9216 - val_loss: 0.3112\n",
            "Epoch 28/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.1670 - val_accuracy: 0.9216 - val_loss: 0.3132\n",
            "Epoch 29/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9478 - loss: 0.1393 - val_accuracy: 0.9216 - val_loss: 0.3068\n",
            "Epoch 30/30\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.1906 - val_accuracy: 0.9314 - val_loss: 0.2998\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     KÄ±rmÄ±zÄ±       0.91      1.00      0.95        49\n",
            "        SarÄ±       1.00      0.94      0.97        98\n",
            "       YeÅŸil       0.97      0.98      0.98       107\n",
            "\n",
            "    accuracy                           0.97       254\n",
            "   macro avg       0.96      0.97      0.97       254\n",
            "weighted avg       0.97      0.97      0.97       254\n",
            "\n",
            "Model ve scaler baÅŸarÄ±yla kaydedildi.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# === 1. VERÄ°YÄ° YÃœKLE ===\n",
        "df = pd.read_csv(\"data.csv\", encoding=\"ISO-8859-1\", sep=\";\")\n",
        "\n",
        "# === 2. Hedef DeÄŸiÅŸkeni Grupla ===\n",
        "def map_ktas(value):\n",
        "    if value in [1, 2]:\n",
        "        return 0  # kÄ±rmÄ±zÄ±\n",
        "    elif value == 3:\n",
        "        return 1  # sarÄ±\n",
        "    elif value in [4, 5]:\n",
        "        return 2  # yeÅŸil\n",
        "    return np.nan\n",
        "\n",
        "df['target'] = df['KTAS_expert'].apply(map_ktas)\n",
        "\n",
        "# === 3. Veri TemizliÄŸi ===\n",
        "df = df.replace(\",\", \".\", regex=True)  # sayÄ±sal virgÃ¼lleri noktaya Ã§evir\n",
        "df = df.drop(columns=['Chief_complain', 'Diagnosis in ED', 'KTAS_expert'])\n",
        "df = df.apply(pd.to_numeric, errors='coerce')  # tÃ¼m veriyi sayÄ±sala Ã§evir\n",
        "df = df.fillna(df.mean(numeric_only=True))     # eksikleri ortalama ile doldur\n",
        "\n",
        "# === 4. Ã–zellik ve Etiket AyÄ±r ===\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# === 5. EÄŸitim/Test AyrÄ±mÄ± ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# === 6. Normalizasyon ===\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# === 7. One-hot encoding (Keras iÃ§in) ===\n",
        "y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "y_test_cat = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# === 8. MLP Modeli ===\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# === 9. EÄŸit ===\n",
        "model.fit(X_train, y_train_cat, epochs=30, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# === 10. DeÄŸerlendirme ===\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=[\"KÄ±rmÄ±zÄ±\", \"SarÄ±\", \"YeÅŸil\"]))\n",
        "# === 11. Modeli ve scaler'Ä± kaydet ===\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Modeli kaydet (HDF5 formatÄ±)\n",
        "model.save(\"triage_model.h5\")\n",
        "\n",
        "# Scaler'Ä± kaydet (pickle formatÄ±)\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "print(\"Model ve scaler baÅŸarÄ±yla kaydedildi.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# === MODEL YÃœKLE ===\n",
        "model = load_model(\"/content/triage_model.h5\")\n",
        "scaler = joblib.load(\"/content/scaler.pkl\")\n",
        "\n",
        "renk_map = {0: \"ğŸ”´ KÄ±rmÄ±zÄ± (Acil)\", 1: \"ğŸŸ¡ SarÄ± (Orta)\", 2: \"ğŸŸ¢ YeÅŸil (DÃ¼ÅŸÃ¼k)\"}\n",
        "\n",
        "# === SEÃ‡ENEKLERÄ°N SAYISAL KARÅILIKLARI ===\n",
        "cinsiyet_map = {\"Erkek\": 1, \"KadÄ±n\": 2}\n",
        "gelis_map = {\n",
        "    \"YÃ¼rÃ¼yerek geldi\": 1,\n",
        "    \"Ambulans ile geldi\": 2,\n",
        "    \"BaÅŸka saÄŸlÄ±k kurumundan sevk\": 3\n",
        "}\n",
        "travma_map = {\"HayÄ±r (TravmasÄ±z)\": 1, \"Evet (TravmalÄ±)\": 2}\n",
        "cikis_map = {\n",
        "    \"Acilde kaldÄ± / Ayaktan taburcu\": 1,\n",
        "    \"YatÄ±ÅŸ yaptÄ± veya baÅŸka yere sevk edildi\": 2\n",
        "}\n",
        "\n",
        "# === TAHMÄ°N FONKSÄ°YONU ===\n",
        "def tahmin_et(\n",
        "    grup, cinsiyet, yas, saatlik_hasta, gelis, travma, mental, agri_var,\n",
        "    nrs, sbp, dbp, hr, rr, bt, spo2, ktas_rn, cikis, hata, kalis_dk, sure_dk, yanlis_mi\n",
        "):\n",
        "    veri = {\n",
        "        \"Group\": 1 if grup == \"YetiÅŸkin\" else 2,\n",
        "        \"Sex\": cinsiyet_map[cinsiyet],\n",
        "        \"Age\": yas,\n",
        "        \"Patients number per hour\": saatlik_hasta,\n",
        "        \"Arrival mode\": gelis_map[gelis],\n",
        "        \"Injury\": travma_map[travma],\n",
        "        \"Mental\": mental,\n",
        "        \"Pain\": agri_var,\n",
        "        \"NRS_pain\": nrs,\n",
        "        \"SBP\": sbp,\n",
        "        \"DBP\": dbp,\n",
        "        \"HR\": hr,\n",
        "        \"RR\": rr,\n",
        "        \"BT\": bt,\n",
        "        \"Saturation\": spo2,\n",
        "        \"KTAS_RN\": ktas_rn,\n",
        "        \"Disposition\": cikis_map[cikis],\n",
        "        \"Error_group\": hata,\n",
        "        \"Length of stay_min\": kalis_dk,\n",
        "        \"KTAS duration_min\": sure_dk,\n",
        "        \"mistriage\": yanlis_mi\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame([veri])\n",
        "    scaled = scaler.transform(df)\n",
        "    pred = model.predict(scaled)\n",
        "    sinif = np.argmax(pred)\n",
        "    return renk_map[sinif]\n",
        "\n",
        "# === ARAYÃœZ ===\n",
        "app = gr.Interface(\n",
        "    fn=tahmin_et,\n",
        "    inputs=[\n",
        "        gr.Dropdown([\"YetiÅŸkin\", \"Ã‡ocuk\"], label=\"Hasta grubu\"),\n",
        "        gr.Dropdown([\"Erkek\", \"KadÄ±n\"], label=\"Cinsiyet\"),\n",
        "        gr.Number(label=\"YaÅŸ (Ã¶rnek: 65)\"),\n",
        "        gr.Number(label=\"Saatlik hasta yoÄŸunluÄŸu (Ã¶rnek: 5)\"),\n",
        "        gr.Dropdown([\"YÃ¼rÃ¼yerek geldi\", \"Ambulans ile geldi\", \"BaÅŸka saÄŸlÄ±k kurumundan sevk\"], label=\"HastanÄ±n geliÅŸ ÅŸekli\"),\n",
        "        gr.Dropdown([\"HayÄ±r (TravmasÄ±z)\", \"Evet (TravmalÄ±)\"], label=\"Hastada travma var mÄ±?\"),\n",
        "        gr.Number(label=\"Zihinsel durum (1: Normal, 2: BilinÃ§ bulanÄ±klÄ±ÄŸÄ±)\", value=1),\n",
        "        gr.Number(label=\"AÄŸrÄ±sÄ± var mÄ±? (1: HayÄ±r, 2: Evet)\", value=1),\n",
        "        gr.Number(label=\"AÄŸrÄ± ÅŸiddeti (0â€“10 arasÄ±)\", value=3),\n",
        "        gr.Number(label=\"Sistolik Kan BasÄ±ncÄ± (Ã¶rnek: 120)\"),\n",
        "        gr.Number(label=\"Diastolik Kan BasÄ±ncÄ± (Ã¶rnek: 80)\"),\n",
        "        gr.Number(label=\"NabÄ±z (Ã¶rnek: 75)\"),\n",
        "        gr.Number(label=\"Solunum SayÄ±sÄ± (Ã¶rnek: 16)\"),\n",
        "        gr.Number(label=\"VÃ¼cut IsÄ±sÄ± (Â°C, Ã¶rnek: 36.8)\"),\n",
        "        gr.Number(label=\"Oksijen Saturasyonu (Ã¶rnek: 98)\"),\n",
        "        gr.Number(label=\"HemÅŸire KTAS PuanÄ± (1â€“5)\", value=3),\n",
        "        gr.Dropdown([\"Acilde kaldÄ± / Ayaktan taburcu\", \"YatÄ±ÅŸ yaptÄ± veya baÅŸka yere sevk edildi\"], label=\"Ã‡Ä±kÄ±ÅŸ durumu\"),\n",
        "        gr.Number(label=\"Hata grubu (Ã¶rnek: 2)\"),\n",
        "        gr.Number(label=\"Hastanede kalÄ±ÅŸ sÃ¼resi (dakika)\", value=60),\n",
        "        gr.Number(label=\"KTAS deÄŸerlendirme sÃ¼resi (dakika)\", value=5.0),\n",
        "        gr.Number(label=\"YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma mÄ±? (1=Evet, 0=HayÄ±r)\", value=0)\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"ğŸ©º Tahmin Edilen Aciliyet Seviyesi\"),\n",
        "    title=\"ğŸ¥ Acil Triage Tahmin UygulamasÄ±\",\n",
        "    description=\"AÅŸaÄŸÄ±daki hasta bilgilerini girerek sistemin tahmin ettiÄŸi aciliyet dÃ¼zeyini (KÄ±rmÄ±zÄ±, SarÄ±, YeÅŸil) Ã¶ÄŸrenebilirsiniz.\"\n",
        ")\n",
        "\n",
        "app.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "7l36VU5fbr3x",
        "outputId": "fea77bbe-afcb-4214-b07d-eda7ca782c86"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e2e3d6f64b498da16c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e2e3d6f64b498da16c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}